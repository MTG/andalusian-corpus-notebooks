{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arab-Andalusian Corpus - Nawba Recognition using Templates from Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook computes several experiments, in order to evaluate the performance of nawba recognition algorithms based on templates derived from scores. Each template is synthesized, using Gaussian distributions, from several folded pitch class distributions belonging to a nawba. The folded pitch distribution of a track is compared to the templates and the best match predicts the nawba. \n",
    "The experiments test different distance measures and standard deviation values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization (MANDATORY)\n",
    "In this cell, all the libraries are loaded. \n",
    "Furthermore, a function checks if the metadata related to Arab-Andalusian corpus of Dunya has been downloaded: if not, all metadata will be downloaded. \n",
    "At the end, the code creates an object to manage the Dunya metadata.\n",
    "\n",
    "#### NB: Before to run, remember to add the Dunya token in the costants.py file. This file is in the directory \"utilities\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "import numpy as np\n",
    "\n",
    "from shutil import copyfile\n",
    "from utilities.recordingcomputation import *\n",
    "from utilities.dunyautilities import *\n",
    "from utilities.metadataStatistics import *\n",
    "from utilities.generalutilities import *\n",
    "from utilities.experiments import *\n",
    "\n",
    "# download metadata from Dunya\n",
    "if not check_dunya_metadata():\n",
    "    print(\"Downloading metadata from Dunya...\")\n",
    "    collect_metadata()\n",
    "\n",
    "# create an object with all the well-structured metadata\n",
    "print(\"Analyzing Dunya Metadata...\")\n",
    "cm = CollectionMetadata()\n",
    "print(\"Collection of metadata created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation (MANDATORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An empty object to manage the dataset of the experiments is created.\n",
    "Then, a list of recordings is imported from a CSV and added to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty object\n",
    "do = DataSet(cm)\n",
    "csv_filename = \"dataset_nawba_77_recordings.csv\" #\"dataset_test.csv\" \"dataset_nawba_77_recordings.csv\"\n",
    "# add recording mbids of an external file in the dataset \n",
    "do.import_dataset_from_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nawba Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters of the experiments are defined. An object is created for every experiment and added to a list.\n",
    "The distance measure parameters are: \"city block (L1)\", \"euclidean (L2)\", \"correlation\", \"canberra\".\n",
    "Standard deviation values tested are 20, 30 and 40, but they could be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_measures_list = [\"euclidean (L2)\"] #[\"city block (L1)\", \"euclidean (L2)\", \"correlation\", \"canberra\"]\n",
    "random_state = 20\n",
    "std_list = [30] #[20,30,40]\n",
    "esperiment_name = \"nr_L2_20_30_with_correct_nawba\"\n",
    "source_dir = os.path.join(EXPERIMENT_DIR, esperiment_name)\n",
    "sub_esperiment_suffix = \"exp\"\n",
    "\n",
    "experiment_list = list()\n",
    "for i_element in range(7):  \n",
    "    sub_esperiment_name = \"{}_{}\".format(sub_esperiment_suffix, i_element + 1)\n",
    "    experiment_list.append(Nawba_Recognition_Experiment(do, i_element, random_state, std_list, distance_measures_list, sub_esperiment_name, source_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, the experiments will be computed. If the plot_flag is True, the plots of templates and of best matches will be stored in the experiment directory as PNGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "plot_flag = True\n",
    "zip_path = \"dataset_nawba_77_recordings.zip\"\n",
    "\n",
    "# check if all the necessary files related to each recording of the dataset are available. \n",
    "recordings_with_missing_files = experiment_list[0].get_recordings_without_experiment_files()\n",
    "# If not import the file from zip\n",
    "if len(recordings_with_missing_files) != 0:\n",
    "    extract_files_from_zip(RECORDINGS_DIR, zip_path)\n",
    "    # second check after unzip\n",
    "    recordings_with_missing_files = experiment_list[0].get_recordings_without_experiment_files()\n",
    "    if len(recordings_with_missing_files) != 0:\n",
    "        raise Exception (\"A/some file/s is/are missing\")\n",
    "\n",
    "# run the experiment\n",
    "for index in range(len(experiment_list)):\n",
    "    name = \"exp_{} results: \".format(counter)\n",
    "    print()\n",
    "    print(name)\n",
    "    experiment_list[index].run(plot_flag=plot_flag)\n",
    "    experiment_list[index].compute_summary()\n",
    "    print()\n",
    "    print(experiment_list[index].df_summary )\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall results will be computed and exported in a CSV stored the experiment directory. The confusion matrix of the best parameters combination will be plotted in a PNG file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and print overall results\n",
    "df_overall =  experiment_list[0].df_summary\n",
    "for index in range(len(experiment_list)-1):\n",
    "    df_overall = df_overall.add(experiment_list[index+1].df_summary)\n",
    "df_overall = df_overall.divide(len(experiment_list))\n",
    "print(df_overall)\n",
    "\n",
    "# export the results\n",
    "export_overall_experiment(experiment_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
