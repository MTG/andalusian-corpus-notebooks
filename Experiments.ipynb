{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arab-Andalusian Collection - Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inizialization (MANDATORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "import numpy as np\n",
    "\n",
    "from utilities.recordingcomputation import *\n",
    "from utilities.dunyautilities import *\n",
    "from utilities.metadataStatistics import *\n",
    "from utilities.generalutilities import *\n",
    "from utilities.experiments import *\n",
    "from gui.gui_corpora import *\n",
    "from gui.gui_analysis import *\n",
    "\n",
    "# download metadata from Dunya\n",
    "if not check_dunya_metadata():\n",
    "    print(\"Downloading metadata from Dunya...\")\n",
    "    collect_metadata()\n",
    "\n",
    "# create an object with all the well-structured metadata\n",
    "print(\"Analyzing Dunya Metadata...\")\n",
    "cm = CollectionMetadata()\n",
    "print(\"Collection of metadata created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define parameters and create the Dataset object (MANDATORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAB_DATASET = [1, 2, 3, 5, 9, 10, 14, 16, 18] #\n",
    "TAB_FUNDAMENTAL_GRADE_IT = [\"DO\", \"RE\", \"RE\", \"RE\", \"DO\", \"RE\", \"DO\", \"RE\", \"DO\"]\n",
    "TAB_FUNDAMENTAL_GRADE = [ \"C\", \"D\", \"D\", \"D\", \"C\", \"D\", \"C\", \"D\", \"C\"]\n",
    "TAB_FUNDAMENTAL_GRADE_DICT = dict(zip(TAB_DATASET, TAB_FUNDAMENTAL_GRADE))\n",
    "SCALE_TAB = [[1,9,14,18],[2,5,10,16],[3]] #\n",
    "\n",
    "experiment_name = \"tab_scale_exp_12_auc_9tab_correction5\"\n",
    "dataset_csv_path = os.path.join(EXPERIMENT_DIR, \"dataset_rmbid_list.csv\")\n",
    "dataset_rmbid_list = cm.import_rmbid_list_from_file(dataset_csv_path)\n",
    "do = DataSet(cm, experiment_name, dataset_rmbid_list, TAB_DATASET, SCALE_TAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tab - Scale Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create experiment object and divide the dataset in training set and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state_list = range(20,30)\n",
    "std_list = [30]#[20,30,40]\n",
    "experiment_list = list()\n",
    "counter = 0\n",
    "for i in random_state_list:\n",
    "    if counter < 1:\n",
    "        experiment_list.append(Tab_Scale_Recognition_Experiment(do, 0.3, i, std_list))\n",
    "    counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(experiment_list)):\n",
    "    experiment_list[index].run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get summary of the results of every experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(experiment_list)):\n",
    "    experiment_list[index].compute_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the overall results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall =  experiment_list[0].df_summary\n",
    "for index in range(len(experiment_list)-1)\n",
    "    df_overall = df_overall.add(experiment_list[index+1].df_summary)\n",
    "df_overall = df_overall.divide(len(experiment_list))\n",
    "print(df_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
